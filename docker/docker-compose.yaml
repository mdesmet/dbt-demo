version: "3.9"
   
services:

  jaffle_webshop:
    image: postgres:11
    container_name: jaffle_webshop
    volumes:
      - ./jaffle_webshop/init-customers.sql:/docker-entrypoint-initdb.d/init-customers.sql
      - ./jaffle_webshop/raw_customers.csv:/home/dump/raw_customers.csv
      - ./jaffle_webshop/init-payments.sql:/docker-entrypoint-initdb.d/init-payments.sql
      - ./jaffle_webshop/raw_payments.csv:/home/dump/raw_payments.csv
      - ./jaffle_webshop/init-orders.sql:/docker-entrypoint-initdb.d/init-orders.sql
      - ./jaffle_webshop/raw_orders.csv:/home/dump/raw_orders.csv
      - ./jaffle_webshop/init-sessions.sql:/docker-entrypoint-initdb.d/init-sessions.sql
      - ./jaffle_webshop/raw_sessions.csv:/home/dump/raw_sessions.csv
    environment:
      - POSTGRES_DB=postgres
      - POSTGRES_USER=postgres
      - POSTGRES_PASSWORD=postgres
    ports:
      - "15432:5432"

  mongodb:
    image: 'mongo:latest'
    hostname: mongodb
    container_name: mongodb
    ports:
      - '27017:27017'
    volumes:
      - ./click_stream/initdb.js:/docker-entrypoint-initdb.d/initdb.js

  trino:
    hostname: trino
    container_name: trino
    image: "starburstdata/starburst-enterprise:402-e.0"
    ports:
      - '8080:8080'
    volumes:
      - ./starburst/etc:/etc/starburst
      - ./catalog:/etc/starburst/catalog

  metastore_db:
    image: postgres:11
    hostname: metastore_db
    container_name: metastore_db
    environment:
      POSTGRES_USER: hive
      POSTGRES_PASSWORD: hive
      POSTGRES_DB: metastore

  hive-metastore:
    container_name: hive-metastore
    hostname: hive-metastore
    image: 'starburstdata/hive:3.1.2-e.15'
    ports:
      - '9083:9083' # Metastore Thrift
    environment:
      HIVE_METASTORE_DRIVER: org.postgresql.Driver
      HIVE_METASTORE_JDBC_URL: jdbc:postgresql://metastore_db:5432/metastore
      HIVE_METASTORE_USER: hive
      HIVE_METASTORE_PASSWORD: hive
      HIVE_METASTORE_WAREHOUSE_DIR: s3://datalake/
      S3_ENDPOINT: http://minio:9000
      S3_ACCESS_KEY: minio
      S3_SECRET_KEY: minio123
      S3_PATH_STYLE_ACCESS: "true"
      REGION: ""
      GOOGLE_CLOUD_KEY_FILE_PATH: ""
      AZURE_ADL_CLIENT_ID: ""
      AZURE_ADL_CREDENTIAL: ""
      AZURE_ADL_REFRESH_URL: ""
      AZURE_ABFS_STORAGE_ACCOUNT: ""
      AZURE_ABFS_ACCESS_KEY: ""
      AZURE_WASB_STORAGE_ACCOUNT: ""
      AZURE_ABFS_OAUTH: ""
      AZURE_ABFS_OAUTH_TOKEN_PROVIDER: ""
      AZURE_ABFS_OAUTH_CLIENT_ID: ""
      AZURE_ABFS_OAUTH_SECRET: ""
      AZURE_ABFS_OAUTH_ENDPOINT: ""
      AZURE_WASB_ACCESS_KEY: ""
    depends_on:
      - metastore_db

  minio:
    hostname: minio
    image: 'minio/minio:RELEASE.2022-05-26T05-48-41Z'
    container_name: minio
    ports:
      - '9000:9000'
      - '9001:9001'
    environment:
      MINIO_ACCESS_KEY: minio
      MINIO_SECRET_KEY: minio123
    command: server /data --console-address ":9001"

  # This job will create the "datalake" bucket on Minio
  mc-job:
    image: 'minio/mc:RELEASE.2022-05-09T04-08-26Z'
    container_name: mc-job
    entrypoint: |
      /bin/bash -c "
      sleep 5;
      /usr/bin/mc config --quiet host add myminio http://minio:9000 minio minio123;
      /usr/bin/mc mb --quiet myminio/datalake
      "
    depends_on:
      - minio

networks:
  trino-network:
    driver: bridge            
